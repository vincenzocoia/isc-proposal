# Success
<!-- 
Projects should have a definition of done that is measurable, and a thorough understanding going in of what the risks are to delivery 
-->


## Definition of done
<!-- 
What does success look like? 
-->

Milestone 1: The distribution object is refactored so that:

- Users are able to make a continuous or discrete distribution object using their own code.
- Users are able to specify parameters to a distribution, forming a distribution _family_. They can resolve these parameters to either create a sub-family, or isolate an exact distribution.

Milestone 2: Some things will need rewiring to connect to the new distribution structure.

- Creation of standard probability distributions (like `dst_norm()`, `dst_gev()`) are rewired and pass unit tests.
- Distribution evaluation functions (like `mean()`, `eval_density()`, `eval_cdf()`, ...) are rewired and pass unit tests.
- Distribution evaluation functions calculated by a "bridge" from another property have been rewired and pass unit tests -- for example, quantiles are calculated through a cumulative distribution function. **Only existing bridges in the distionary package will be used; no new ones will be created.
- Functions to determine discrete points in a distribution (e.g., `next_discrete()`) are rewired and pass unit tests.

Milestone 3: Some additional hygiene and overhead would be useful to budget for, too:

- Creation of unit tests around the new construct of a distribution _family_ (when the parameters are not resolved).
- Creation of unit tests that have not been made yet for existing functionality.
- Updating the documentation (function level, package level, etc.)
- Cleanup and submit to CRAN.

## Measuring success
<!-- 
How will we know when success is achieved, what markers can we use along the way 
-->

Success is described above, but we can use the three milestones as the key markers. 

## Future work
<!-- 
How could this be extended / developed in the future by yourself and/or the community in general?
-->

I have big plans for the probaverse, so development will continue, through some means.

Immediate future work:

- Right away, I will be adding unit tests to distplyr and submitting that to CRAN -- I anticipate little to no rewiring needed there.
- With hopeful funding soon from BGC, I can execute my design for the **couple** package.

Then:

- Advances in **famish** by spearheading some package designs (this is the most frankenstein-like package in the probaverse currently).
- Empirical distributions are sufficiently complex that they justify their own package (currently empirical distributions are narrow and simple).
- Advances in **distionary** by adding user-defined ways to evaluate a distribution. This can be done by defining a "representation" object and building bridges to other representations through a network.

## Key risks
<!-- 
What sort of things could come up that can delay or break the project?

 - [ ] People
 - [ ] Processes
 - [ ] Tooling & Technology
 - [ ] Costs

-->

The biggest risk is if the design I have planned for refactoring the distribution object doesn't work. But this is easily mitigated by adjusting or simplifying the design, and getting community feedback. Ultimately, the lowest bar is to put **distionary** on CRAN, so I could easily change the design to be more like the current design if need be.

The other risk is that it's just me on the project:

- This could lead to poor package design if I'm the only one providing input. But I'll be seeking early feedback from ROpenSci, and I imagine the ISC can help here, too.
- The project could get delayed because of sickness or some other issue that shows up, but this is unlikely. The worst case scenario is that BGC can't include the probaverse in our FFA manual -- not the end of the world since the probaverse is still useful.
- From your perspective, you probably haven't been in touch with me yet, which can generate a host of worries. I hope I'm able to convey how serious I am about this software and how capable I am through this proposal.